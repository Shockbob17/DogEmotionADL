{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters in deep learning to tune are \n",
    "- the number of neurons\n",
    "- activation function\n",
    "- optimiser\n",
    "- learning rate\n",
    "- batch size\n",
    "- epochs \n",
    "- number of layers.\n",
    "\n",
    "\n",
    "Reference: \n",
    "- https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported. Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Optional, Callable\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision.models import efficientnet_b5, EfficientNet_B5_Weights\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "print(\"Libraries imported. Using device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "This is adapted from SeparatingData.ipynb\n",
    "Download the processed dataset from Google Drive is yet to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(data_dir: str, zip_url: str, zip_filename: str, root_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Download and extract the dataset from Google Drive if it doesn't exist\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Directory where the dataset zip file will be stored\n",
    "        zip_url (str): URL of the dataset zip file\n",
    "        zip_filename (str): Name for the downloaded zip file\n",
    "        root_dir (str): Directory where the dataset will be extracted\n",
    "    \"\"\"\n",
    "    # Create the data directory if it doesn't exist.\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "        print(f\"Created directory: {root_dir}\")\n",
    "\n",
    "    # Check if the dataset is already extracted.\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Downloading dataset from {zip_url} to {zip_filename}\")\n",
    "        gdown.download(zip_url, zip_filename, quiet=False)\n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(root_dir)\n",
    "        print(f\"Extraction complete. Dataset available at {data_dir}\")\n",
    "    else:\n",
    "        print(f\"Dataset already exists at {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at ../input/train_images_4_class\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../input/train_images_4_class\"\n",
    "ZIP_URL = \"https://drive.google.com/uc?id=1DiCQ52XyU40nwl5JC6B2nUBVYQrrpFl4\"\n",
    "ZIP_FILENAME = \"../input/train_images_4_class.zip\"\n",
    "ROOT_DIR = \"../input\"\n",
    "\n",
    "download_dataset(DATA_DIR, ZIP_URL, ZIP_FILENAME, ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Data Load\n",
    "For fasting hyperparameter tuning, use a subset of the dataset to find the most optimised set of hyperparameters.\n",
    "Loads dataset from processed dataset which should have been split to train, test, eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tuning_data_loaders(\n",
    "    dataset_root: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int = 32,\n",
    "    subset_fraction: float = 0.1,\n",
    "    random_seed: int = 42\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \"\"\"Creates DataLoaders for hyperparameter tuning using a subset of the dataset.\n",
    "\n",
    "    If the dataset_root directory contains subfolders 'train', 'eval', and 'test',\n",
    "    these are loaded directly. Otherwise, the full dataset is loaded and randomly split.\n",
    "    In either case, a subset of each split is sampled for faster tuning.\n",
    "\n",
    "    Note:\n",
    "      The transform provided is applied to each image as it is loaded by ImageFolder.\n",
    "      Even if the images in the pre-split folders have been preprocessed externally,\n",
    "      it is common to store raw images and apply transforms on the fly.\n",
    "\n",
    "    Args:\n",
    "        dataset_root (str): Root directory of the dataset. This should either be the parent\n",
    "            folder of the split directories or the folder containing all images.\n",
    "        transform (transforms.Compose): Transformations to apply to the dataset.\n",
    "        batch_size (int, optional): Batch size for DataLoaders. Defaults to 32.\n",
    "        subset_fraction (float, optional): Fraction of each split to use for tuning. Defaults to 0.1.\n",
    "        random_seed (int, optional): Random seed for reproducibility. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, DataLoader, DataLoader]: DataLoaders for training, validation, and test subsets.\n",
    "    \"\"\"\n",
    "    # Check if dataset_root contains pre-split 'train', 'eval', and 'test' subdir\n",
    "    split_dirs = ['train', 'eval', 'test']\n",
    "    if all(os.path.exists(os.path.join(dataset_root, sub)) for sub in split_dirs):\n",
    "        train_dataset = datasets.ImageFolder(root=os.path.join(dataset_root, 'train'), transform=transform)\n",
    "        print(f\"Full train dataset: {len(train_dataset)}\")\n",
    "        val_dataset = datasets.ImageFolder(root=os.path.join(dataset_root, 'eval'), transform=transform)\n",
    "        print(f\"Full val dataset: {len(val_dataset)}\")\n",
    "        test_dataset = datasets.ImageFolder(root=os.path.join(dataset_root, 'test'), transform=transform)\n",
    "        print(f\"Full test dataset: {len(test_dataset)}\")\n",
    "\n",
    "    else:\n",
    "        # If not pre-split, load the full dataset and split it randomly\n",
    "        full_dataset = datasets.ImageFolder(root=dataset_root, transform=transform)\n",
    "        total_len = len(full_dataset)\n",
    "        train_len = int(0.7 * total_len)\n",
    "        val_len = int(0.15 * total_len)\n",
    "        test_len = total_len - train_len - val_len\n",
    "        train_dataset, val_dataset, test_dataset = random_split(\n",
    "            full_dataset, [train_len, val_len, test_len],\n",
    "            generator=torch.Generator().manual_seed(random_seed)\n",
    "        )\n",
    "\n",
    "    def sample_subset(dataset, fraction):\n",
    "        \"\"\"Returns a subset of the dataset with the specified fraction of examples.\"\"\"\n",
    "        dataset_len = len(dataset)\n",
    "        subset_size = max(1, int(fraction * dataset_len))\n",
    "        indices = random.sample(range(dataset_len), subset_size)\n",
    "        return Subset(dataset, indices)\n",
    "\n",
    "    # Sample a subset from each split\n",
    "    if subset_fraction < 1.0:\n",
    "        subset_train_dataset = sample_subset(train_dataset, subset_fraction)\n",
    "        print(f\"Subset-train dataset: {len(train_dataset)}\")\n",
    "        subset_val_dataset = sample_subset(val_dataset, subset_fraction)\n",
    "        print(f\"Subset-val dataset: {len(val_dataset)}\")\n",
    "        subset_test_dataset = sample_subset(test_dataset, subset_fraction)\n",
    "        print(f\"Subset-test dataset: {len(test_dataset)}\")\n",
    "\n",
    "    subset_train_loader = DataLoader(subset_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    subset_val_loader = DataLoader(subset_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    subset_test_loader = DataLoader(subset_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return subset_train_loader, subset_val_loader, subset_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset: 8033\n",
      "Full val dataset: 1719\n",
      "Full test dataset: 1726\n",
      "Subset-train dataset: 8033\n",
      "Subset-val dataset: 1719\n",
      "Subset-test dataset: 1726\n",
      "DataLoaders for hyperparameter tuning are ready.\n"
     ]
    }
   ],
   "source": [
    "SPLIT_DATASET = os.path.abspath(\"../input/actual\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Define a transform. \n",
    "# In this notebook, we assume we doing it for EfficientNetB5, so we resize to ~456x456\n",
    "weights = EfficientNet_B5_Weights.DEFAULT\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((456, 456)),\n",
    "        transforms.ToTensor(),\n",
    "        weights.transforms()  # applies normalization as required\n",
    "    ])\n",
    "\n",
    "TRAIN_LOADER, VAL_LOADER, TEST_LOADER = create_tuning_data_loaders(\n",
    "    dataset_root=SPLIT_DATASET,\n",
    "    transform=transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset_fraction=0.1,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"DataLoaders for hyperparameter tuning are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specifications\n",
    "This is where you should replace with your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB5 Partial Transfer Learning:\n",
    "- https://discuss.pytorch.org/t/partial-transfer-learning-efficientnet/109689 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEfficientNetB5(nn.Module):\n",
    "    \"\"\"EfficientNetB5 model for transfer learning on the dog emotion dataset\n",
    "    with a configurable classification head for hyperparameter tuning, \n",
    "    i.e parameters you wish to tune need to be specified\n",
    "\n",
    "    This model uses a pretrained EfficientNetB5 backbone and replaces its\n",
    "    classifier with a multi-layer fully connected network whose architecture\n",
    "    can be tuned (number of layers, neurons, and activation function)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_classes: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 freeze_backbone: bool = False,\n",
    "                 hidden_sizes: Optional[List[int]] = None,\n",
    "                 activation: str = 'relu') -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            dropout (float): Dropout rate to apply in the classifier.\n",
    "            freeze_backbone (bool): If True, freeze the backbone layers.\n",
    "            hidden_sizes (Optional[List[int]]): List of sizes for hidden layers in the classifier.\n",
    "                If None, a single linear layer is used.\n",
    "            activation (str): Activation function to use in the classifier ('relu', 'tanh', etc.).\n",
    "        \"\"\"\n",
    "        super(BaseEfficientNetB5, self).__init__()\n",
    "        weights = EfficientNet_B5_Weights.DEFAULT\n",
    "        self.backbone = efficientnet_b5(weights=weights)\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Build the classifier based on the provided hidden_sizes\n",
    "        layers = []\n",
    "        input_dim = in_features\n",
    "        if hidden_sizes:\n",
    "            for hidden_dim in hidden_sizes:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(self._get_activation(activation))\n",
    "                input_dim = hidden_dim\n",
    "            # final classification layer.\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        else:\n",
    "            # single linear layer if no hidden layers specified\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        \n",
    "        self.backbone.classifier[1] = nn.Sequential(*layers)\n",
    "    \n",
    "    def _get_activation(self, activation: str) -> Callable:\n",
    "        \"\"\"Returns an activation function based on the given string.\n",
    "\n",
    "        Args:\n",
    "            activation (str): Name of the activation function.\n",
    "\n",
    "        Returns:\n",
    "            Callable: Activation function module.\n",
    "        \"\"\"\n",
    "        if activation.lower() == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation.lower() == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated: BaseEfficientNetB5\n"
     ]
    }
   ],
   "source": [
    "model = BaseEfficientNetB5(num_classes=4, dropout=0.3, freeze_backbone=True, hidden_sizes=[256, 128], activation='relu')\n",
    "print(\"Model instantiated:\", model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "This is the part where you write the training function and load it to the ray tune scheduler.\n",
    "For this execution, ASHAscheduler is used with Optuna for bayesian optimisation techniques - which should be using the default Tree-Structured Parzen Estimator.\n",
    "If many parameters, this is would be more efficient than grid search and random search.\n",
    "\n",
    "References:\n",
    "- https://docs.ray.io/en/latest/tune/examples/includes/async_hyperband_example.html\n",
    "- https://docs.ray.io/en/latest/tune/examples/tune-pytorch-cifar.html \n",
    "- https://docs.ray.io/en/latest/tune/examples/includes/mnist_pytorch.html\n",
    "- https://docs.ray.io/en/latest/tune/api/suggestion.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ray import tune\n",
    "\n",
    "CHECKPOINT_DIR = os.path.abspath(\"../models/hyptune\")\n",
    "def train_model(config, checkpoint_dir=CHECKPOINT_DIR, data_dir=None):\n",
    "    \"\"\"Training function for Ray Tune hyperparameter tuning.\n",
    "\n",
    "    This function instantiates the model with hyperparameters\n",
    "    specified in the config dictionary, trains the model on the global TRAIN_LOADER,\n",
    "    evaluates on VAL_LOADER, and reports the validation loss to Ray Tune.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Hyperparameter configuration. Expected keys include:\n",
    "            - lr (float): Learning rate.\n",
    "            - weight_decay (float): Weight decay for the optimizer.\n",
    "            - dropout (float): Dropout rate for the classifier.\n",
    "            - hidden_sizes (list or None): List of hidden layer sizes in the classifier.\n",
    "            - activation (str): Activation function to use ('relu', 'tanh', etc.).\n",
    "            - freeze_backbone (bool): Whether to freeze the model backbone.\n",
    "            - num_epochs (int): Number of training epochs.\n",
    "            - optimiser (callable, optional): Optimiser class. Default is optim.Adam.\n",
    "            - criterion (callable, optional): Loss function instance. Default is nn.CrossEntropyLoss().\n",
    "        checkpoint_dir (str, optional): Directory for checkpointing (if applicable).\n",
    "        data_dir (str, optional): Not used here; included for compatibility.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        print(f\"Checkpoint Folder exists\")\n",
    "    \n",
    "    # instantiate model with hyperparameters from config\n",
    "    model = BaseEfficientNetB5(\n",
    "        num_classes=4,\n",
    "        dropout=config.get(\"dropout\", 0.2),\n",
    "        freeze_backbone=config.get(\"freeze_backbone\", True),\n",
    "        hidden_sizes=config.get(\"hidden_sizes\", None),\n",
    "        activation=config.get(\"activation\", \"relu\")\n",
    "    ).to(device)\n",
    "    \n",
    "    optimiser_class = config.get(\"optimiser\", optim.Adam)\n",
    "    optimiser = optimiser_class(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = config.get(\"criterion\", nn.CrossEntropyLoss())\n",
    "\n",
    "    num_epochs = config.get(\"num_epochs\", 2)  # a low number for quick tuning, but update accordingly\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in tqdm(TRAIN_LOADER, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(TRAIN_LOADER.dataset)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # Optionally, checkpoint the model.\n",
    "        if checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, f\"checkpoint_{epoch}.pt\")\n",
    "            torch.save(model.state_dict(), path)\n",
    "    \n",
    "    # Evaluation on the validation set\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in VAL_LOADER:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    avg_val_loss = total_loss / len(VAL_LOADER.dataset)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # Report the metric to Ray Tune.\n",
    "    tune.report({\"loss\": avg_val_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-04-06 04:27:56</td></tr>\n",
       "<tr><td>Running for: </td><td>00:30:39.09        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.4/18.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 90.000: None | Iter 30.000: None | Iter 10.000: None<br>Logical resource usage: 2.0/11 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  dropout</th><th>freeze_backbone  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_8c6f8dad</td><td>TERMINATED</td><td>127.0.0.1:29051</td><td style=\"text-align: right;\"> 0.392798</td><td>True             </td><td style=\"text-align: right;\">0.000132929</td><td style=\"text-align: right;\">   0.00635122 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1835.63</td><td style=\"text-align: right;\">1.36224</td></tr>\n",
       "<tr><td>train_model_18671d32</td><td>TERMINATED</td><td>127.0.0.1:29056</td><td style=\"text-align: right;\"> 0.162398</td><td>True             </td><td style=\"text-align: right;\">0.000625137</td><td style=\"text-align: right;\">   4.20799e-06</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1835.87</td><td style=\"text-align: right;\">1.30187</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=29051)\u001b[0m Checkpoint Folder exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "Epoch 1/2:   8%|▊         | 1/13 [01:08<13:39, 68.32s/it]\n",
      "Epoch 1/2:   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "Epoch 1/2:  15%|█▌        | 2/13 [02:15<12:26, 67.89s/it]\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Epoch 1/2:  23%|██▎       | 3/13 [03:22<11:14, 67.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  31%|███       | 4/13 [04:29<10:05, 67.25s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  38%|███▊      | 5/13 [05:36<08:56, 67.03s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  46%|████▌     | 6/13 [06:42<07:46, 66.60s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  54%|█████▍    | 7/13 [07:48<06:38, 66.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  62%|██████▏   | 8/13 [08:54<05:31, 66.33s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  69%|██████▉   | 9/13 [10:00<04:24, 66.14s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  77%|███████▋  | 10/13 [11:06<03:18, 66.11s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  85%|████████▍ | 11/13 [12:12<02:12, 66.18s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1/2:  92%|█████████▏| 12/13 [13:18<01:06, 66.27s/it]\n",
      "Epoch 1/2:  85%|████████▍ | 11/13 [12:12<02:12, 66.19s/it]\n",
      "Epoch 1/2: 100%|██████████| 13/13 [13:56<00:00, 64.36s/it]\n",
      "Epoch 1/2:  92%|█████████▏| 12/13 [13:18<01:06, 66.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=29051)\u001b[0m Epoch 1/2, Training Loss: 1.3845\n",
      "\u001b[36m(train_model pid=29056)\u001b[0m Checkpoint Folder exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2:   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "Epoch 2/2:   8%|▊         | 1/13 [01:07<13:24, 67.02s/it]\n",
      "Epoch 1/2: 100%|██████████| 13/13 [13:56<00:00, 64.32s/it]\n",
      "Epoch 2/2:   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "Epoch 2/2:  15%|█▌        | 2/13 [02:12<12:08, 66.21s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  23%|██▎       | 3/13 [03:18<10:59, 65.97s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  31%|███       | 4/13 [04:24<09:53, 65.98s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  38%|███▊      | 5/13 [05:31<08:50, 66.29s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  46%|████▌     | 6/13 [06:37<07:43, 66.22s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  54%|█████▍    | 7/13 [07:44<06:38, 66.45s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  62%|██████▏   | 8/13 [08:50<05:31, 66.38s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  69%|██████▉   | 9/13 [09:56<04:24, 66.25s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  77%|███████▋  | 10/13 [11:02<03:18, 66.33s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  85%|████████▍ | 11/13 [12:09<02:13, 66.52s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 2/2:  92%|█████████▏| 12/13 [13:15<01:06, 66.34s/it]\n",
      "Epoch 2/2:  85%|████████▍ | 11/13 [12:10<02:13, 66.52s/it]\n",
      "Epoch 2/2: 100%|██████████| 13/13 [13:52<00:00, 64.06s/it]\n",
      "Epoch 2/2:  92%|█████████▏| 12/13 [13:16<01:06, 66.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=29051)\u001b[0m Epoch 2/2, Training Loss: 1.3708\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=29051)\u001b[0m /Users/huiningonn/anaconda3/envs/dogemotion/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(train_model pid=29051)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "Epoch 2/2: 100%|██████████| 13/13 [13:53<00:00, 64.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=29051)\u001b[0m Validation Loss: 1.3622\n",
      "\u001b[36m(train_model pid=29056)\u001b[0m Epoch 2/2, Training Loss: 1.2704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 04:27:56,224\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/huiningonn/ray_results/train_model_2025-04-06_03-57-16' in 0.0034s.\n",
      "2025-04-06 04:27:56,227\tINFO tune.py:1041 -- Total run time: 1839.11 seconds (1839.08 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'lr': 0.0006251373574521745, 'weight_decay': 4.2079886696066345e-06, 'dropout': 0.16239780813448107, 'freeze_backbone': True, 'num_epochs': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=29056)\u001b[0m /Users/huiningonn/anaconda3/envs/dogemotion/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(train_model pid=29056)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=29056)\u001b[0m Validation Loss: 1.3019\n"
     ]
    }
   ],
   "source": [
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='loss',\n",
    "    mode='min',\n",
    "    max_t=100,           # max training iterations per trial\n",
    "    grace_period=10,     # min iterations before stopping\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "optuna_search = OptunaSearch(metric=\"loss\", mode=\"min\", seed=42)\n",
    "\n",
    "# define search space in a config dictionary, i.e what are the values you want to try, this is just example of format\n",
    "'''\n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"dropout\": tune.uniform(0.1, 0.5),\n",
    "    \"hidden_sizes\": tune.choice([[256, 128], [512, 256], None]),\n",
    "    \"activation\": tune.choice([\"relu\", \"tanh\"]),\n",
    "    \"freeze_backbone\": tune.choice([True, False]),\n",
    "    \"num_epochs\": 2, \n",
    "    \"optimiser\": tune.choice([optim.Adam, optim.SGD]),\n",
    "    \"criterion\": tune.choice([nn.CrossEntropyLoss, nn.NLLLoss]),\n",
    "}\n",
    "'''\n",
    "\n",
    "# this is what i specified for the example because i am running on cpu\n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"dropout\": tune.uniform(0.1, 0.5),\n",
    "    \"freeze_backbone\": tune.choice([True]),\n",
    "    \"num_epochs\": 2,\n",
    "}\n",
    "\n",
    "# tuner object\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(train_model, {\"cpu\": 2, \"gpu\": 0}), # specify based on the device u using because by default it uses all, i.e if u have 4 cpus; it does 4 concurrent trials\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=asha_scheduler,\n",
    "        search_alg=optuna_search,\n",
    "        num_samples=2,  # number of trials to run\n",
    "    ),\n",
    "    run_config=tune.RunConfig(verbose=1),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "print(\"Best config:\", results.get_best_result(metric=\"loss\", mode=\"min\").config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogemotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
