{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58fe304b",
   "metadata": {},
   "source": [
    "# Model Demo file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c65a32c",
   "metadata": {},
   "source": [
    "In this file, there is code to load and run the best models of the various architectures created by the team.\n",
    "\n",
    "**This notebook contains the following sections:**\n",
    "\n",
    "1. EfficientNetB5\n",
    "2. DINOv2\n",
    "3. Swin\n",
    "4. EfficientNetB5 + SE + ASF (ENSE)\n",
    "5. EfficientNetB5 + SE + ASF + DINOv2\n",
    "6. EfficientNetB5 + SE + ASF + Swin (ENSESwin)\n",
    "\n",
    "**Assumed project structure:**\n",
    "```markdown\n",
    "ROOT\n",
    "├── notebooks                                       <-- folder with the notebooks\n",
    "│   ├── modelDemo.ipynb                             <-- current notebook used for demonstrating models\n",
    "│   └── ...                                      \n",
    "│\n",
    "├── models                                          <-- folder with the models\n",
    "│   ├── DINOv2\n",
    "│   │   └── DINOv2_best_model.pt                    \n",
    "│   ├── ENSE\n",
    "│   │   └── ENSE_best_model.pt                      \n",
    "│   ├── ENSESwin\n",
    "│   │   └── ENSESwin_best_model.pt                  \n",
    "│   ├── FINAL_EfficientNetB5\n",
    "│   │   └── FINAL_EfficientNetB5_best_model.pt      \n",
    "│   ├── FINAL_EfficientNetDINOv2\n",
    "│   │   └── FINAL_EfficientNetDINOv2_best_model.pt  \n",
    "│   └── FINAL_Swin\n",
    "│      └── FINAL_Swin_best_model.pt    \n",
    "│            \n",
    "└── input                                           <-- folder with the dataset\n",
    "    └── final_split_15Apr2025                       <-- preprocessed dataset from drive\n",
    "        ├── train\n",
    "        ├── eval\n",
    "        └── test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55224d22",
   "metadata": {},
   "source": [
    "Configurable Variables:\n",
    "- **root (str)**: Root directory of the project (commonly set to '..').\n",
    "- **data_set_directory (str)**: Name of the directory containing all datasets (i.e.,'input')\n",
    "- **root_result_folder (str)**: Top-level directory name for storing evaluation results.\n",
    "- **model_directory (str)**: Directory name where all trained models will be saved.\n",
    "- **final_data_set (str)**: Folder name of the final processed and augmented dataset used for training.\n",
    "\n",
    "- **images_to_print (str)**: The number of images to be explictly printed with labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f97e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Panel to adjust variables\n",
    "root = \"..\"\n",
    "data_set_directory = \"input\"\n",
    "root_result_folder = \"results\"\n",
    "model_directory = \"models\" \n",
    "final_data_set = \"final_split_15Apr2025\"\n",
    "\n",
    "images_to_print= 3\n",
    "batch_size = 64 # State the number of datapoints in each batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e48623",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa984b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yongl\\anaconda3\\envs\\ADLTEAM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Callable\n",
    "import os\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b5, EfficientNet_B5_Weights\n",
    "import random\n",
    "import torchvision.transforms.functional as F\n",
    "from timm.models.swin_transformer import SwinTransformer\n",
    "\n",
    "\n",
    "# Determine the project root - required to import DataHandler from utils folder\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), root))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from utils.DataHandler import download_dataset, create_full_data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8436a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CUDA (GPU)\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = os.path.join(PROJECT_ROOT, root_result_folder)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "DATASET_FOLDER = os.path.join(root, data_set_directory,final_data_set)\n",
    "\n",
    "MODELS_BASE_DIR = os.path.join(root, model_directory)\n",
    "\n",
    "ROOT_DATA_DIR = os.path.join(root, data_set_directory)\n",
    "\n",
    "# Gets the device to be used\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using device: CUDA (GPU)\")\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        print(\"Using device: MPS (Apple Silicon GPU)\")\n",
    "        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        print(\"Using device: CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696646ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download the processed dataset used by the team\n",
    "download_dataset(final_data_set,f\"https://drive.google.com/uc?id=1XhSO100qgRuLEyopfb7-4gBp0CRjZkfg\",  F\"{DATASET_FOLDER}.zip\", ROOT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfcdb80",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16326d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING FULL DATASET-------------------------------------------------------\n",
      "Using pre-split datasets: train 8025, val 579, test 572\n"
     ]
    }
   ],
   "source": [
    "SPLIT_DATASET = os.path.abspath(DATASET_FOLDER)\n",
    "BATCH_SIZE = batch_size\n",
    "\n",
    "# Define data transformation \n",
    "# in this notebook, we are doing it for EfficientNetB5, so we resize to ~456x456\n",
    "weights = EfficientNet_B5_Weights.DEFAULT\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((456, 456)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])])\n",
    "\n",
    "print(\"LOADING FULL DATASET-------------------------------------------------------\")\n",
    "# Creating dataloader to load the full dataset for training the actual models and testing\n",
    "FULL_TRAIN_LOADER, FULL_VAL_LOADER, FULL_TEST_LOADER = create_full_data_loaders(\n",
    "    dataset_root=SPLIT_DATASET,\n",
    "    transform=transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b070e7b9",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940b5b1",
   "metadata": {},
   "source": [
    "### EfficientNetB5\n",
    "This section contains code to download the best model for the base EfficientNetB5 architecture as well as run it on a predefined dataset above and print several images from the dataset with their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcdee3d",
   "metadata": {},
   "source": [
    "#### Model Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32160fa",
   "metadata": {},
   "source": [
    "#### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da10810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEfficientNetB5(nn.Module):\n",
    "    \"\"\"EfficientNetB5 model for transfer learning on the dog emotion dataset\n",
    "    with a configurable classification head for hyperparameter tuning, \n",
    "    i.e parameters you wish to tune need to be specified\n",
    "\n",
    "    This model uses a pretrained EfficientNetB5 backbone and replaces its\n",
    "    classifier with a multi-layer fully connected network whose architecture\n",
    "    can be tuned (number of layers, neurons, and activation function)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_classes: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 freeze_backbone: bool = False,\n",
    "                 hidden_sizes: Optional[List[int]] = None,\n",
    "                 activation: str = 'relu') -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            dropout (float): Dropout rate to apply in the classifier.\n",
    "            freeze_backbone (bool): If True, freeze the backbone layers.\n",
    "            hidden_sizes (Optional[List[int]]): List of sizes for hidden layers in the classifier.\n",
    "                If None, a single linear layer is used.\n",
    "            activation (str): Activation function to use in the classifier ('relu', 'tanh', etc.).\n",
    "        \"\"\"\n",
    "        super(BaseEfficientNetB5, self).__init__()\n",
    "        weights = EfficientNet_B5_Weights.DEFAULT\n",
    "        self.backbone = efficientnet_b5(weights=weights)\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Build the classifier based on the provided hidden_sizes\n",
    "        layers = []\n",
    "        input_dim = in_features\n",
    "        if hidden_sizes:\n",
    "            for hidden_dim in hidden_sizes:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(self._get_activation(activation))\n",
    "                input_dim = hidden_dim\n",
    "            # final classification layer\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        else:\n",
    "            # single linear layer if no hidden layers specified\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        \n",
    "        self.backbone.classifier[1] = nn.Sequential(*layers)\n",
    "    \n",
    "    def _get_activation(self, activation: str) -> Callable:\n",
    "        \"\"\"Returns an activation function based on the given string.\n",
    "\n",
    "        Args:\n",
    "            activation (str): Name of the activation function.\n",
    "\n",
    "        Returns:\n",
    "            Callable: Activation function module.\n",
    "        \"\"\"\n",
    "        if activation.lower() == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation.lower() == 'leakyrelu':\n",
    "            return nn.LeakyReLU()\n",
    "        elif activation.lower() == 'gelu':\n",
    "            return nn.GELU()\n",
    "        elif activation.lower() == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c362770",
   "metadata": {},
   "source": [
    "#### Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c88541",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BaseEfficientNetB5:\n\tUnexpected key(s) in state_dict: \"backbone.classifier.1.4.weight\", \"backbone.classifier.1.4.bias\", \"backbone.classifier.1.7.weight\", \"backbone.classifier.1.7.bias\". \n\tsize mismatch for backbone.classifier.1.1.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([4, 2048]).\n\tsize mismatch for backbone.classifier.1.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([4]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# load best model from training\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_drectory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINAL_EfficientNetB5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODELS_BASE_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_drectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_drectory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_best_model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m final_model\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      6\u001b[0m final_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\yongl\\anaconda3\\envs\\ADLTEAM\\lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BaseEfficientNetB5:\n\tUnexpected key(s) in state_dict: \"backbone.classifier.1.4.weight\", \"backbone.classifier.1.4.bias\", \"backbone.classifier.1.7.weight\", \"backbone.classifier.1.7.bias\". \n\tsize mismatch for backbone.classifier.1.1.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([4, 2048]).\n\tsize mismatch for backbone.classifier.1.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([4])."
     ]
    }
   ],
   "source": [
    "final_model = BaseEfficientNetB5()\n",
    "# load best model from training\n",
    "model_drectory = \"ENSE\"\n",
    "final_model.load_state_dict(torch.load(os.path.join(MODELS_BASE_DIR, model_drectory, f\"{model_drectory}_best_model.pt\")))\n",
    "final_model.to(DEVICE)\n",
    "final_model.eval()\n",
    "\n",
    "# initialise metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in FULL_TEST_LOADER:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = final_model(images)\n",
    "        # for test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        # for accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy()) # move to cpu to ensure compatibility because numpy only operates on cpu\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(FULL_TEST_LOADER.dataset)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "logging.info(\"Test Loss: %.4f, Test Accuracy: %.2f%%\", test_loss, test_accuracy * 100)\n",
    "\n",
    "# generate and log classification report\n",
    "class_names = FULL_TEST_LOADER.dataset.classes\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "logging.info(\"Classification Report:\\n%s\", report)\n",
    "\n",
    "# print f1, precision, recall scores\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "prec = precision_score(all_labels, all_preds, average='macro')\n",
    "rec = recall_score(all_labels, all_preds, average='macro')\n",
    "print(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "logging.info(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# save confusion matrix as image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "conf_matrix_path = os.path.join(RESULTS_DIR, model_directory, \"confusion_matrix.png\")\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.show(fig)\n",
    "\n",
    "logging.info(\"Confusion matrix saved to: %s\", conf_matrix_path)\n",
    "\n",
    "# Get random indices\n",
    "random_indices = random.sample(range(len(FULL_TEST_LOADER.dataset)), images_to_print)\n",
    "\n",
    "# Get the corresponding samples and labels\n",
    "fig, axes = plt.subplots(1, images_to_print, figsize=(15, 5))\n",
    "final_model.eval()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = FULL_TEST_LOADER.dataset[idx]\n",
    "    image_input = image.unsqueeze(0).to(DEVICE)\n",
    "    output = final_model(image_input)\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "    # Move image to CPU and unnormalize if needed (assuming normalization was applied)\n",
    "    image = F.to_pil_image(image)\n",
    "\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"True: {class_names[label]}\\nPred: {class_names[predicted_label.item()]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdbdb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c927113",
   "metadata": {},
   "source": [
    "### DINOv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c50642",
   "metadata": {},
   "source": [
    "#### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee50595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDINOv2(nn.Module):\n",
    "    \"\"\"DINOv2 model for transfer learning on the dog emotion dataset\n",
    "    with a configurable classification head for hyperparameter tuning, \n",
    "    i.e parameters you wish to tune need to be specified\n",
    "\n",
    "    This model uses a pretrained DINOv2 backbone and replaces its\n",
    "    classifier with a multi-layer fully connected network whose architecture\n",
    "    can be tuned (number of layers, neurons, and activation function)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model_variant: str = 'dinov2_vits14',\n",
    "                 num_classes: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 freeze_backbone: bool = False,\n",
    "                 hidden_sizes: Optional[List[int]] = None,\n",
    "                 activation: str = 'relu') -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_variant(str): the version of DINOv2 to load.\n",
    "            num_classes (int): Number of output classes.\n",
    "            dropout (float): Dropout rate to apply in the classifier.\n",
    "            freeze_backbone (bool): If True, freeze the backbone layers.\n",
    "            hidden_sizes (Optional[List[int]]): List of sizes for hidden layers in the classifier.\n",
    "                If None, a single linear layer is used.\n",
    "            activation (str): Activation function to use in the classifier ('relu', 'tanh', etc.).\n",
    "        \"\"\"\n",
    "        super(BaseDINOv2, self).__init__()\n",
    "\n",
    "        # load DINOv2 backbone from Torch Hub\n",
    "        self.backbone = torch.hub.load('facebookresearch/dinov2', model_variant)\n",
    "        in_features = self.backbone.embed_dim  # e.g., 768 for vitb14, 384 for vits14\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Build the classifier based on the provided hidden_sizes\n",
    "        layers = []\n",
    "        input_dim = in_features\n",
    "        if hidden_sizes:\n",
    "            for hidden_dim in hidden_sizes:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(self._get_activation(activation))\n",
    "                input_dim = hidden_dim\n",
    "            # final classification layer\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        else:\n",
    "            # single linear layer if no hidden layers specified\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        \n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "    \n",
    "    def _get_activation(self, activation: str) -> Callable:\n",
    "        \"\"\"Returns an activation function based on the given string.\n",
    "\n",
    "        Args:\n",
    "            activation (str): Name of the activation function.\n",
    "\n",
    "        Returns:\n",
    "            Callable: Activation function module.\n",
    "        \"\"\"\n",
    "        if activation.lower() == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation.lower() == 'leakyrelu':\n",
    "            return nn.LeakyReLU()\n",
    "        elif activation.lower() == 'gelu':\n",
    "            return nn.GELU()\n",
    "        elif activation.lower() == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec36c94",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = BaseDINOv2()\n",
    "# load best model from training\n",
    "model_drectory = \"DINOv2\"\n",
    "final_model.load_state_dict(torch.load(os.path.join(MODELS_BASE_DIR, model_drectory, f\"{model_drectory}_best_model.pt\")))\n",
    "final_model.to(DEVICE)\n",
    "final_model.eval()\n",
    "\n",
    "# initialise metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in FULL_TEST_LOADER:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = final_model(images)\n",
    "        # for test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        # for accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy()) # move to cpu to ensure compatibility because numpy only operates on cpu\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(FULL_TEST_LOADER.dataset)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "logging.info(\"Test Loss: %.4f, Test Accuracy: %.2f%%\", test_loss, test_accuracy * 100)\n",
    "\n",
    "# generate and log classification report\n",
    "class_names = FULL_TEST_LOADER.dataset.classes\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "logging.info(\"Classification Report:\\n%s\", report)\n",
    "\n",
    "# print f1, precision, recall scores\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "prec = precision_score(all_labels, all_preds, average='macro')\n",
    "rec = recall_score(all_labels, all_preds, average='macro')\n",
    "print(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "logging.info(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# save confusion matrix as image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "conf_matrix_path = os.path.join(RESULTS_DIR, model_directory, \"confusion_matrix.png\")\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.show(fig)\n",
    "\n",
    "logging.info(\"Confusion matrix saved to: %s\", conf_matrix_path)\n",
    "\n",
    "# Get random indices\n",
    "random_indices = random.sample(range(len(FULL_TEST_LOADER.dataset)), images_to_print)\n",
    "\n",
    "# Get the corresponding samples and labels\n",
    "fig, axes = plt.subplots(1, images_to_print, figsize=(15, 5))\n",
    "final_model.eval()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = FULL_TEST_LOADER.dataset[idx]\n",
    "    image_input = image.unsqueeze(0).to(DEVICE)\n",
    "    output = final_model(image_input)\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "    # Move image to CPU and unnormalize if needed (assuming normalization was applied)\n",
    "    image = F.to_pil_image(image)\n",
    "\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"True: {class_names[label]}\\nPred: {class_names[predicted_label.item()]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669b356",
   "metadata": {},
   "source": [
    "### Swin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c53ef",
   "metadata": {},
   "source": [
    "#### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6189b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSwin(nn.Module):\n",
    "    \"\"\"Swin model for transfer learning on the dog emotion dataset\n",
    "    with a configurable classification head for hyperparameter tuning, \n",
    "    i.e parameters you wish to tune need to be specified\n",
    "\n",
    "    This model uses a pretrained Swin backbone and replaces its\n",
    "    classifier with a multi-layer fully connected network whose architecture\n",
    "    can be tuned (number of layers, neurons, and activation function)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model_variant: str = 'swin_base_patch4_window7_224',\n",
    "                 num_classes: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 freeze_backbone: bool = False,\n",
    "                 hidden_sizes: Optional[List[int]] = None,\n",
    "                 activation: str = 'relu') -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_variant(str): the version of Swin to load.\n",
    "            num_classes (int): Number of output classes.\n",
    "            dropout (float): Dropout rate to apply in the classifier.\n",
    "            freeze_backbone (bool): If True, freeze the backbone layers.\n",
    "            hidden_sizes (Optional[List[int]]): List of sizes for hidden layers in the classifier.\n",
    "                If None, a single linear layer is used.\n",
    "            activation (str): Activation function to use in the classifier ('relu', 'tanh', etc.).\n",
    "        \"\"\"\n",
    "        super(BaseSwin, self).__init__()\n",
    "\n",
    "        # load Swin backbone from timm\n",
    "        self.backbone = timm.create_model(\n",
    "            model_variant,\n",
    "            pretrained=True,\n",
    "            num_classes=0,     # disable head\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        \n",
    "        in_features = self.backbone.num_features\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Build the classifier based on the provided hidden_sizes\n",
    "        layers = []\n",
    "        input_dim = in_features\n",
    "        if hidden_sizes:\n",
    "            for hidden_dim in hidden_sizes:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(self._get_activation(activation))\n",
    "                input_dim = hidden_dim\n",
    "            # final classification layer.\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        else:\n",
    "            # single linear layer if no hidden layers specified\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        \n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "    \n",
    "    def _get_activation(self, activation: str) -> Callable:\n",
    "        \"\"\"Returns an activation function based on the given string.\n",
    "\n",
    "        Args:\n",
    "            activation (str): Name of the activation function.\n",
    "\n",
    "        Returns:\n",
    "            Callable: Activation function module.\n",
    "        \"\"\"\n",
    "        if activation.lower() == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation.lower() == 'leakyrelu':\n",
    "            return nn.LeakyReLU()\n",
    "        elif activation.lower() == 'gelu':\n",
    "            return nn.GELU()\n",
    "        elif activation.lower() == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d254402c",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939cc0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = BaseSwin()\n",
    "# load best model from training\n",
    "model_drectory = \"FINAL_Swin\"\n",
    "final_model.load_state_dict(torch.load(os.path.join(MODELS_BASE_DIR, model_drectory, f\"{model_drectory}_best_model.pt\")))\n",
    "final_model.to(DEVICE)\n",
    "final_model.eval()\n",
    "\n",
    "# initialise metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in FULL_TEST_LOADER:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = final_model(images)\n",
    "        # for test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        # for accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy()) # move to cpu to ensure compatibility because numpy only operates on cpu\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(FULL_TEST_LOADER.dataset)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "logging.info(\"Test Loss: %.4f, Test Accuracy: %.2f%%\", test_loss, test_accuracy * 100)\n",
    "\n",
    "# generate and log classification report\n",
    "class_names = FULL_TEST_LOADER.dataset.classes\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "logging.info(\"Classification Report:\\n%s\", report)\n",
    "\n",
    "# print f1, precision, recall scores\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "prec = precision_score(all_labels, all_preds, average='macro')\n",
    "rec = recall_score(all_labels, all_preds, average='macro')\n",
    "print(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "logging.info(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# save confusion matrix as image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "conf_matrix_path = os.path.join(RESULTS_DIR, model_directory, \"confusion_matrix.png\")\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.show(fig)\n",
    "\n",
    "logging.info(\"Confusion matrix saved to: %s\", conf_matrix_path)\n",
    "\n",
    "# Get random indices\n",
    "random_indices = random.sample(range(len(FULL_TEST_LOADER.dataset)), images_to_print)\n",
    "\n",
    "# Get the corresponding samples and labels\n",
    "fig, axes = plt.subplots(1, images_to_print, figsize=(15, 5))\n",
    "final_model.eval()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = FULL_TEST_LOADER.dataset[idx]\n",
    "    image_input = image.unsqueeze(0).to(DEVICE)\n",
    "    output = final_model(image_input)\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "    # Move image to CPU and unnormalize if needed (assuming normalization was applied)\n",
    "    image = F.to_pil_image(image)\n",
    "\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"True: {class_names[label]}\\nPred: {class_names[predicted_label.item()]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0b328",
   "metadata": {},
   "source": [
    "### EfficientNetB5 + SE + ASF (ENSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac6ebd",
   "metadata": {},
   "source": [
    "#### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d7c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation (SE) block for channel-wise feature recalibration.\n",
    "\n",
    "    This block implements the SE mechanism which adaptively recalibrates \n",
    "    channel-wise feature responses by explicitly modeling interdependencies \n",
    "    between channels.\n",
    "\n",
    "    Args:\n",
    "        channels (int): Number of input and output channels.\n",
    "        reduction_ratio (int): Reduction ratio for the intermediate hidden layer. \n",
    "            Controls the bottleneck in the SE block (default: 16).\n",
    "\n",
    "    Forward Input:\n",
    "        x (Tensor): Input feature map of shape (batch_size, channels, height, width).\n",
    "\n",
    "    Forward Output:\n",
    "        Tensor: Output feature map of the same shape, with recalibrated channel responses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, reduction_ratio=16):\n",
    "        super(SqueezeExcitationBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.interaction = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction_ratio, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.interaction(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class AttentionalSelectiveFusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Attentional Selective Fusion (ASF) Block for Channel-wise Feature Recalibration.\n",
    "\n",
    "    This module enhances the representational capacity of convolutional neural networks\n",
    "    by applying a lightweight channel attention mechanism. It uses global average pooling\n",
    "    followed by a bottleneck transformation and sigmoid activation to compute \n",
    "    per-channel attention weights. The input tensor is then modulated by these weights,\n",
    "    selectively emphasizing informative features.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input and output channels in the input feature map.\n",
    "\n",
    "    Forward Input:\n",
    "        x (torch.Tensor): Feature map of shape (batch_size, in_channels, height, width)\n",
    "\n",
    "    Forward Output:\n",
    "        torch.Tensor: Recalibrated feature map of the same shape as input\"\"\"\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc  = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,  in_channels // 16, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 16, in_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.fc(self.avg(x))\n",
    "        return x * w\n",
    "    \n",
    "class SEEfficientNetB5(nn.Module):\n",
    "    \"\"\"\n",
    "    EfficientNetB5-based classifier with optional Squeeze-and-Excitation (SE) block, \n",
    "    customizable classifier head, and partial layer unfreezing for fine-tuning.\n",
    "\n",
    "    Designed for flexibility during hyperparameter tuning (e.g., with Ray Tune).\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of output classes. Default is 4.\n",
    "        dropout (float): Dropout probability used in the classifier head. Default is 0.2.\n",
    "        hidden_sizes (Optional[List[int]]): List of hidden layer sizes for the classifier head. \n",
    "            If None, no additional hidden layers are added beyond the SE block (if used).\n",
    "        activation (str): Activation function to use in the classifier head. \n",
    "            Supported values: 'relu', 'tanh', 'sigmoid'. Default is 'relu'.\n",
    "        use_se (bool): Whether to include a Squeeze-and-Excitation (SE) block before the classifier. Default is True.\n",
    "        unfreeze_blocks (Optional[List[int]]): List of block indices in EfficientNetB5's features to unfreeze \n",
    "            for fine-tuning. If None, the entire backbone remains frozen.\n",
    "\n",
    "    Notes:\n",
    "        - The SE block is applied to the flattened output of the backbone if `use_se` is True.\n",
    "        - The classifier head is built dynamically based on `hidden_sizes` and activation.\n",
    "        - The EfficientNetB5 backbone is loaded with pretrained weights by default.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_classes: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 hidden_sizes: Optional[List[int]] = None,\n",
    "                 activation: str = 'relu',\n",
    "                 use_se: bool = True,\n",
    "                 unfreeze_blocks: Optional[List[int]] = None) -> None:\n",
    "        \"\"\"\n",
    "        Initializes an instance of the model with the specified configuration.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int, optional): The number of output classes for the model. Default is 4.\n",
    "            dropout (float, optional): The dropout rate to be applied to the model. Default is 0.2.\n",
    "            hidden_sizes (List[int], optional): A list specifying the sizes of hidden layers in the model.\n",
    "                                                If None, the model will use a default configuration. Default is None.\n",
    "            activation (str, optional): The activation function to use in the model. Default is 'relu'.\n",
    "                                        Other possible values might include 'sigmoid', 'tanh', etc.\n",
    "            use_se (bool, optional): Whether or not to use the Squeeze-and-Excitation (SE) block in the model. \n",
    "                                        Default is True.\n",
    "            unfreeze_blocks (List[int], optional): A list of blocks to be unfrozen during training.\n",
    "                                                    Default is None, which means no blocks are unfrozen.\n",
    "\n",
    "        \"\"\"\n",
    "        super(SEEfficientNetB5, self).__init__()\n",
    "        weights = EfficientNet_B5_Weights.DEFAULT\n",
    "        self.backbone = efficientnet_b5(weights=weights)\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "\n",
    "        # Setting the values layers in the efficientnet backbone that will be frozen\n",
    "        for param in self.backbone.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        if unfreeze_blocks:\n",
    "            for idx in unfreeze_blocks:\n",
    "                for param in self.backbone.features[idx].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        # Build the classifier head with the SE and additional layers according to the number of layers in the hidden state\n",
    "        layers = []\n",
    "        if use_se:\n",
    "            layers.extend([\n",
    "                nn.Unflatten(1, (in_features, 1, 1)),\n",
    "                SqueezeExcitationBlock(in_features),\n",
    "                AttentionalSelectiveFusion(in_features),\n",
    "                nn.Flatten()\n",
    "            ])\n",
    "        \n",
    "        input_dim = in_features\n",
    "        if hidden_sizes:\n",
    "            for hidden_dim in hidden_sizes:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(self._get_activation(activation))\n",
    "                input_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Dropout(p=dropout))\n",
    "        layers.append(nn.Linear(input_dim, num_classes))\n",
    "\n",
    "        self.backbone.classifier[1] = nn.Sequential(*layers)\n",
    "\n",
    "    def _get_activation(self, activation: str) -> Callable:\n",
    "        \"\"\"\n",
    "        Returns the specified activation function from PyTorch's nn module.\n",
    "\n",
    "        Args:\n",
    "            activation (str): Name of the activation function. Supported values are\n",
    "                'relu', 'tanh', and 'sigmoid' (case-insensitive).\n",
    "\n",
    "        Returns:\n",
    "            Callable: The corresponding activation function module (e.g., nn.ReLU()).\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unsupported activation function name is provided.\n",
    "        \"\"\"\n",
    "        if activation.lower() == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation.lower() == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9ffa4",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d3404",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# for test loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 23\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# for accuracy\u001b[39;00m\n\u001b[0;32m     25\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_model = SEEfficientNetB5()\n",
    "# load best model from training\n",
    "model_drectory = \"ENSE\"\n",
    "final_model.load_state_dict(torch.load(os.path.join(MODELS_BASE_DIR, model_drectory, f\"{model_drectory}_best_model.pt\")))\n",
    "final_model.to(DEVICE)\n",
    "final_model.eval()\n",
    "\n",
    "# initialise metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in FULL_TEST_LOADER:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = final_model(images)\n",
    "        # for test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        # for accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy()) # move to cpu to ensure compatibility because numpy only operates on cpu\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(FULL_TEST_LOADER.dataset)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "logging.info(\"Test Loss: %.4f, Test Accuracy: %.2f%%\", test_loss, test_accuracy * 100)\n",
    "\n",
    "# generate and log classification report\n",
    "class_names = FULL_TEST_LOADER.dataset.classes\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "logging.info(\"Classification Report:\\n%s\", report)\n",
    "\n",
    "# print f1, precision, recall scores\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "prec = precision_score(all_labels, all_preds, average='macro')\n",
    "rec = recall_score(all_labels, all_preds, average='macro')\n",
    "print(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "logging.info(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# save confusion matrix as image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "conf_matrix_path = os.path.join(RESULTS_DIR, model_directory, \"confusion_matrix.png\")\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.show(fig)\n",
    "\n",
    "logging.info(\"Confusion matrix saved to: %s\", conf_matrix_path)\n",
    "\n",
    "# Get random indices\n",
    "random_indices = random.sample(range(len(FULL_TEST_LOADER.dataset)), images_to_print)\n",
    "\n",
    "# Get the corresponding samples and labels\n",
    "fig, axes = plt.subplots(1, images_to_print, figsize=(15, 5))\n",
    "final_model.eval()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = FULL_TEST_LOADER.dataset[idx]\n",
    "    image_input = image.unsqueeze(0).to(DEVICE)\n",
    "    output = final_model(image_input)\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "    # Move image to CPU and unnormalize if needed (assuming normalization was applied)\n",
    "    image = F.to_pil_image(image)\n",
    "\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"True: {class_names[label]}\\nPred: {class_names[predicted_label.item()]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b6a37",
   "metadata": {},
   "source": [
    "### EfficientNetB5 + SE + ASF+ DINOv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5050245",
   "metadata": {},
   "source": [
    "#### Model Specifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12226a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction_ratio=16):\n",
    "        super(SqueezeExcitationBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.interaction = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction_ratio, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.interaction(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class AttentionalSelectiveFusion(nn.Module):\n",
    "    \"\"\"Simple channel‑attention fusion block\"\"\"\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc  = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,  in_channels // 16, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 16, in_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.fc(self.avg(x))\n",
    "        return x * w\n",
    "\n",
    "class EfficientNetDINOv2(nn.Module):\n",
    "    \"\"\"Modified EfficientNetB5 with Squeeze and Extraction Blocks for feature extraction;\n",
    "    then DINOv2 model on the dog emotion dataset\n",
    "    with a configurable classification head for hyperparameter tuning, \n",
    "    i.e parameters you wish to tune need to be specified\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_classes: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 freeze_backbone: bool = False,\n",
    "                 hidden_sizes: Optional[List[int]] = None,\n",
    "                 activation: str = 'relu') -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            dropout (float): Dropout rate to apply in the classifier.\n",
    "            freeze_backbone (bool): If True, freeze the backbone layers.\n",
    "            hidden_sizes (Optional[List[int]]): List of sizes for hidden layers in the classifier.\n",
    "                If None, a single linear layer is used.\n",
    "            activation (str): Activation function to use in the classifier ('relu', 'tanh', etc.).\n",
    "        \"\"\"\n",
    "        super(EfficientNetDINOv2, self).__init__()\n",
    "\n",
    "\n",
    "        # load EfficientNet‑B5 backbone\n",
    "        self.backbone = efficientnet_b5(weights=EfficientNet_B5_Weights.DEFAULT).features  # [B, 2048, 7, 7] for 224×224\n",
    "\n",
    "        # freeze backbone\n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "            for name, param in self.backbone.named_parameters():\n",
    "                if \"6\" in name or \"7\" in name:\n",
    "                    param.requires_grad = True #freeze for now cause comp cmi\n",
    "\n",
    "        # SE block\n",
    "        self.se = SqueezeExcitationBlock(2048)\n",
    "\n",
    "        # Attentional Selective Fusion & projection to match DINOv2 model\n",
    "        self.asf   = AttentionalSelectiveFusion(2048)\n",
    "        self.proj  = nn.Conv2d(2048, 384, kernel_size=1)\n",
    "\n",
    "        # force map to 37×37 so token count matches DINOv2‑ViT‑S/14 (1370 = 1+37²)\n",
    "        self.adapt = nn.AdaptiveAvgPool2d((37, 37))\n",
    "\n",
    "        # DINOv2 (ViT‑S/14) without patch embed\n",
    "        self.dino  = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\")\n",
    "        # freeze too\n",
    "        if freeze_backbone:\n",
    "            for param in self.dino.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # build classifier\n",
    "        layers = []\n",
    "        input_dim = self.dino.embed_dim  #should be 384\n",
    "        if hidden_sizes:\n",
    "            for hidden_dim in hidden_sizes:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(self._get_activation(activation))\n",
    "                input_dim = hidden_dim\n",
    "            # final classification layer\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        else:\n",
    "            # single linear layer if no hidden layers specified\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        \n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "\n",
    "    def _get_activation(self, activation: str) -> Callable:\n",
    "        \"\"\"Returns an activation function based on the given string.\n",
    "\n",
    "        Args:\n",
    "            activation (str): Name of the activation function.\n",
    "\n",
    "        Returns:\n",
    "            Callable: Activation function module.\n",
    "        \"\"\"\n",
    "        if activation.lower() == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation.lower() == 'leakyrelu':\n",
    "            return nn.LeakyReLU()\n",
    "        elif activation.lower() == 'gelu':\n",
    "            return nn.GELU()\n",
    "        elif activation.lower() == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # EfficientNet feature map\n",
    "        x = self.backbone(x)          # [B, 2048, 7, 7]\n",
    "        x = self.se(x)\n",
    "        x = self.asf(x)               # attentional fusion\n",
    "        x = self.proj(x)              # [B, 384, 7, 7]\n",
    "        x = self.adapt(x)             # [B, 384, 37, 37]\n",
    "\n",
    "        # transformer expects image to the patch embedding layer, need to bypass\n",
    "        # prepare tokens for DINOv2 transformer\n",
    "        B, C, H, W = x.shape\n",
    "        tokens = x.flatten(2).transpose(1, 2)   # [B, 1369, 384]\n",
    "\n",
    "        # prepend cls token + add positional embedding\n",
    "        cls_tok  = self.dino.cls_token.expand(B, -1, -1)  # [B,1,384]\n",
    "        tokens   = torch.cat((cls_tok, tokens), dim=1)     # [B,1370,384]\n",
    "        tokens   = tokens + self.dino.pos_embed            # match length 1370\n",
    "\n",
    "        # transformer encoder\n",
    "        for blk in self.dino.blocks:\n",
    "            tokens = blk(tokens)\n",
    "        tokens = self.dino.norm(tokens)\n",
    "\n",
    "        # take CLS representation\n",
    "        rep = tokens[:, 0]            # [B, 384]\n",
    "        return self.classifier(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6241389",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = EfficientNetDINOv2()\n",
    "# load best model from training\n",
    "model_drectory = \"FINAL_EfficientNetDINOv2\"\n",
    "final_model.load_state_dict(torch.load(os.path.join(MODELS_BASE_DIR, model_drectory, f\"{model_drectory}_best_model.pt\")))\n",
    "final_model.to(DEVICE)\n",
    "final_model.eval()\n",
    "\n",
    "# initialise metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in FULL_TEST_LOADER:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = final_model(images)\n",
    "        # for test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        # for accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy()) # move to cpu to ensure compatibility because numpy only operates on cpu\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(FULL_TEST_LOADER.dataset)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "logging.info(\"Test Loss: %.4f, Test Accuracy: %.2f%%\", test_loss, test_accuracy * 100)\n",
    "\n",
    "# generate and log classification report\n",
    "class_names = FULL_TEST_LOADER.dataset.classes\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "logging.info(\"Classification Report:\\n%s\", report)\n",
    "\n",
    "# print f1, precision, recall scores\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "prec = precision_score(all_labels, all_preds, average='macro')\n",
    "rec = recall_score(all_labels, all_preds, average='macro')\n",
    "print(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "logging.info(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# save confusion matrix as image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "conf_matrix_path = os.path.join(RESULTS_DIR, model_directory, \"confusion_matrix.png\")\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.show(fig)\n",
    "\n",
    "logging.info(\"Confusion matrix saved to: %s\", conf_matrix_path)\n",
    "\n",
    "# Get random indices\n",
    "random_indices = random.sample(range(len(FULL_TEST_LOADER.dataset)), images_to_print)\n",
    "\n",
    "# Get the corresponding samples and labels\n",
    "fig, axes = plt.subplots(1, images_to_print, figsize=(15, 5))\n",
    "final_model.eval()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = FULL_TEST_LOADER.dataset[idx]\n",
    "    image_input = image.unsqueeze(0).to(DEVICE)\n",
    "    output = final_model(image_input)\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "    # Move image to CPU and unnormalize if needed (assuming normalization was applied)\n",
    "    image = F.to_pil_image(image)\n",
    "\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"True: {class_names[label]}\\nPred: {class_names[predicted_label.item()]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388f9a13",
   "metadata": {},
   "source": [
    "### EfficientNetB5 + SE + ASF + Swin Transformer (ENSESwin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a67ac6",
   "metadata": {},
   "source": [
    "#### Model Specifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84efcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation (SE) block for channel-wise feature recalibration.\n",
    "\n",
    "    This block implements the SE mechanism which adaptively recalibrates \n",
    "    channel-wise feature responses by explicitly modeling interdependencies \n",
    "    between channels.\n",
    "\n",
    "    Args:\n",
    "        channels (int): Number of input and output channels.\n",
    "        reduction_ratio (int): Reduction ratio for the intermediate hidden layer. \n",
    "            Controls the bottleneck in the SE block (default: 16).\n",
    "\n",
    "    Forward Input:\n",
    "        x (Tensor): Input feature map of shape (batch_size, channels, height, width).\n",
    "\n",
    "    Forward Output:\n",
    "        Tensor: Output feature map of the same shape, with recalibrated channel responses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, reduction_ratio=16):\n",
    "        super(SqueezeExcitationBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.interaction = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction_ratio, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.interaction(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class AttentionalSelectiveFusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Attentional Selective Fusion (ASF) Block for Channel-wise Feature Recalibration.\n",
    "\n",
    "    This module enhances the representational capacity of convolutional neural networks\n",
    "    by applying a lightweight channel attention mechanism. It uses global average pooling\n",
    "    followed by a bottleneck transformation and sigmoid activation to compute \n",
    "    per-channel attention weights. The input tensor is then modulated by these weights,\n",
    "    selectively emphasizing informative features.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input and output channels in the input feature map.\n",
    "\n",
    "    Forward Input:\n",
    "        x (torch.Tensor): Feature map of shape (batch_size, in_channels, height, width)\n",
    "\n",
    "    Forward Output:\n",
    "        torch.Tensor: Recalibrated feature map of the same shape as input\"\"\"\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc  = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,  in_channels // 16, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 16, in_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.fc(self.avg(x))\n",
    "        return x * w\n",
    "    \n",
    "\n",
    "class SwinFicientNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 hidden_sizes: Optional[List[int]] = None,\n",
    "                 activation: str = 'relu',\n",
    "                 unfreeze_blocks: Optional[List[int]] = None):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Initializes an instance of the model with the specified configuration.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int, optional): The number of output classes for the model. Default is 4.\n",
    "            dropout (float, optional): The dropout rate to be applied to the model. Default is 0.2.\n",
    "            hidden_sizes (List[int], optional): A list specifying the sizes of hidden layers in the model.\n",
    "                                                If None, the model will use a default configuration. Default is None.\n",
    "            activation (str, optional): The activation function to use in the model. Default is 'relu'.\n",
    "                                        Other possible values might include 'sigmoid', 'tanh', etc.\n",
    "            unfreeze_blocks (List[int], optional): A list of blocks to be unfrozen during training.\n",
    "                                                    Default is None, which means no blocks are unfrozen.\n",
    "\n",
    "        \"\"\"\n",
    "        # 1) EfficientNet-B5 feature extractor only\n",
    "        eff = efficientnet_b5(weights=EfficientNet_B5_Weights.DEFAULT)\n",
    "        self.backbone = eff.features  # <-- 4D conv maps\n",
    "        feat_channels = 2048          # EfficientNetB5's final feature‐map channels\n",
    "\n",
    "        # Freeze all EfficientNet layers, then optionally unfreeze some\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        if unfreeze_blocks:\n",
    "            for idx in unfreeze_blocks:\n",
    "                for p in self.backbone[idx].parameters():\n",
    "                    p.requires_grad = True\n",
    "\n",
    "        # 2) Squeeze‐Excitation on the conv maps\n",
    "        self.se = SqueezeExcitationBlock(feat_channels)\n",
    "        self.asf   = AttentionalSelectiveFusion(2048)\n",
    "\n",
    "        # 3) Project into 96 channels for Swin\n",
    "        self.project    = nn.Conv2d(feat_channels, 96, kernel_size=1)\n",
    "        self.adapt_pool = nn.AdaptiveAvgPool2d((14, 14))\n",
    "\n",
    "        # 4) Swin Transformer head (classifier baked in)\n",
    "        self.swin = SwinTransformer(\n",
    "            img_size=14,\n",
    "            patch_size=1,\n",
    "            in_chans=96,\n",
    "            embed_dim=96,\n",
    "            depths=[2, 2, 6, 2],\n",
    "            num_heads=[3, 6, 12, 24],\n",
    "            window_size=7,\n",
    "            mlp_ratio=4.0,\n",
    "            qkv_bias=True,\n",
    "            drop_path_rate=0.1,\n",
    "            ape=False,\n",
    "            patch_norm=True,\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "        # 5) Optional extra MLP (if you want more hidden layers after Swin)\n",
    "        layers = []\n",
    "        if hidden_sizes:\n",
    "            inp = num_classes\n",
    "            for h in hidden_sizes:\n",
    "                layers += [\n",
    "                    nn.Dropout(dropout),\n",
    "                    nn.Linear(inp, h),\n",
    "                    self._get_activation(activation)\n",
    "                ]\n",
    "                inp = h\n",
    "            layers += [nn.Dropout(dropout), nn.Linear(inp, num_classes)]\n",
    "            self.post_swin = nn.Sequential(*layers)\n",
    "        else:\n",
    "            self.post_swin = nn.Identity()\n",
    "    def _get_activation(self, act: str) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Returns the specified activation function from PyTorch's nn module.\n",
    "\n",
    "        Args:\n",
    "            activation (str): Name of the activation function. Supported values are\n",
    "                'relu', 'tanh', and 'sigmoid' (case-insensitive).\n",
    "\n",
    "        Returns:\n",
    "            Callable: The corresponding activation function module (e.g., nn.ReLU()).\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unsupported activation function name is provided.\n",
    "        \"\"\"\n",
    "        act = act.lower()\n",
    "        return {\n",
    "            'relu'     : nn.ReLU(),\n",
    "            'tanh'     : nn.Tanh(),\n",
    "            'sigmoid'  : nn.Sigmoid(),\n",
    "            'leakyrelu': nn.LeakyReLU()\n",
    "        }[act]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)    # [B, 2048, H, W]\n",
    "        x = self.se(x)          # SE block\n",
    "        x = self.asf(x)         # attentional fusion\n",
    "        x = self.project(x)     # [B,  96, H, W]\n",
    "        x = self.adapt_pool(x)  # [B,  96, 14,14]\n",
    "        x = self.swin(x)        # [B, num_classes]\n",
    "        return self.post_swin(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85c5643",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5102802",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = SwinFicientNet()\n",
    "# load best model from training\n",
    "model_drectory = \"ENSESwin\"\n",
    "final_model.load_state_dict(torch.load(os.path.join(MODELS_BASE_DIR, model_drectory, f\"{model_drectory}_best_model.pt\")))\n",
    "final_model.to(DEVICE)\n",
    "final_model.eval()\n",
    "\n",
    "# initialise metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in FULL_TEST_LOADER:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = final_model(images)\n",
    "        # for test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        # for accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy()) # move to cpu to ensure compatibility because numpy only operates on cpu\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(FULL_TEST_LOADER.dataset)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "logging.info(\"Test Loss: %.4f, Test Accuracy: %.2f%%\", test_loss, test_accuracy * 100)\n",
    "\n",
    "# generate and log classification report\n",
    "class_names = FULL_TEST_LOADER.dataset.classes\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "logging.info(\"Classification Report:\\n%s\", report)\n",
    "\n",
    "# print f1, precision, recall scores\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "prec = precision_score(all_labels, all_preds, average='macro')\n",
    "rec = recall_score(all_labels, all_preds, average='macro')\n",
    "print(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "logging.info(f\"\\n F1 score: {f1}; \\n Precision score: {prec}; \\n Recall Score: {rec}\")\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# save confusion matrix as image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "conf_matrix_path = os.path.join(RESULTS_DIR, model_directory, \"confusion_matrix.png\")\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.show(fig)\n",
    "\n",
    "logging.info(\"Confusion matrix saved to: %s\", conf_matrix_path)\n",
    "\n",
    "# Get random indices\n",
    "random_indices = random.sample(range(len(FULL_TEST_LOADER.dataset)), images_to_print)\n",
    "\n",
    "# Get the corresponding samples and labels\n",
    "fig, axes = plt.subplots(1, images_to_print, figsize=(15, 5))\n",
    "final_model.eval()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = FULL_TEST_LOADER.dataset[idx]\n",
    "    image_input = image.unsqueeze(0).to(DEVICE)\n",
    "    output = final_model(image_input)\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "    # Move image to CPU and unnormalize if needed (assuming normalization was applied)\n",
    "    image = F.to_pil_image(image)\n",
    "\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"True: {class_names[label]}\\nPred: {class_names[predicted_label.item()]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADLTEAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
