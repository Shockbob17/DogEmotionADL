{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters in deep learning to tune are \n",
    "- the number of neurons\n",
    "- activation function\n",
    "- optimiser\n",
    "- learning rate\n",
    "- batch size\n",
    "- epochs \n",
    "- number of layers.\n",
    "\n",
    "\n",
    "Reference: \n",
    "- https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Callable\n",
    "import os\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# determine the project root - required to import DataHandler from utils folder\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# configuring log file\n",
    "log_dir = os.path.join(project_root, \"logs\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_filename = os.path.join(log_dir, \"swin_training_log.txt\") #NOTE: specify based on model training\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=log_filename,\n",
    "    filemode=\"w\",  #NOTE: previous logs would be overwritten\n",
    "    format=\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "MODEL_SAVE_DIR = os.path.join(project_root, \"models\", \"swin\")\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True) \n",
    "\n",
    "RESULTS_SAVE_DIR = os.path.join(project_root, \"results\", \"swin\")\n",
    "os.makedirs(RESULTS_SAVE_DIR, exist_ok=True) \n",
    "\n",
    "from utils.DataHandler import download_dataset, create_full_data_loaders, create_tuning_data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CUDA (GPU)\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using device: CUDA (GPU)\")\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        print(\"Using device: MPS (Apple Silicon GPU)\")\n",
    "        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        print(\"Using device: CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "This is adapted from SeparatingData.ipynb\n",
    "Download the processed dataset from Google Drive if yet to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at ../input/final_split_training_augmented\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../input/final_split_training_augmented\"\n",
    "ZIP_URL = \"https://drive.google.com/uc?id=11t8m703wcNss3w5diJSUGBA_vXnCKChr\"\n",
    "ZIP_FILENAME = \"../input/final_split.zip\"\n",
    "ROOT_DIR = \"../input\"\n",
    "\n",
    "download_dataset(DATA_DIR, ZIP_URL, ZIP_FILENAME, ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Data Load\n",
    "For faster hyperparameter tuning, use a subset of the dataset to find the most optimised set of hyperparameters.\n",
    "Loads dataset from processed dataset which should have been split to train, test, eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-split datasets: train 8025, val 579, test 572\n",
      "Created tuning data loaders with subset fraction: 0.5\n",
      "Created subset datasets for hyperparameter tuning: train 4012, val 289, test 572\n",
      "Class Distribution for Subset Training:\n",
      "  angry     : 983\n",
      "  happy     : 1039\n",
      "  relaxed   : 1024\n",
      "  sad       : 966\n",
      "Class Distribution for Subset Validation:\n",
      "  angry     : 71\n",
      "  happy     : 75\n",
      "  relaxed   : 74\n",
      "  sad       : 69\n"
     ]
    }
   ],
   "source": [
    "SPLIT_DATASET = os.path.abspath(\"../input/final_split_training_augmented\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Define data transformation \n",
    "# in this notebook, we are doing it for Swin, so we resize to ~224x224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "TRAIN_LOADER, VAL_LOADER, TEST_LOADER = create_tuning_data_loaders(\n",
    "    dataset_root=SPLIT_DATASET,\n",
    "    transform=transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset_fraction=0.5,\n",
    "    random_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Data Load\n",
    "When doing the entire training for the entire dataset (full dataset not used in hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-split datasets: train 8025, val 579, test 572\n"
     ]
    }
   ],
   "source": [
    "FULL_TRAIN_LOADER, FULL_VAL_LOADER, FULL_TEST_LOADER = create_full_data_loaders(\n",
    "    dataset_root=SPLIT_DATASET,\n",
    "    transform=transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swin Transformer:\n",
    "- https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/swin_transformer.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSwin(nn.Module):\n",
    "    \"\"\"Swin model for transfer learning on the dog emotion dataset\n",
    "    with a configurable classification head for hyperparameter tuning, \n",
    "    i.e parameters you wish to tune need to be specified\n",
    "\n",
    "    This model uses a pretrained Swin backbone and replaces its\n",
    "    classifier with a multi-layer fully connected network whose architecture\n",
    "    can be tuned (number of layers, neurons, and activation function)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model_variant: str = 'swin_base_patch4_window7_224',\n",
    "                 num_classes: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 freeze_backbone: bool = False,\n",
    "                 hidden_sizes: Optional[List[int]] = None,\n",
    "                 activation: str = 'relu') -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            dropout (float): Dropout rate to apply in the classifier.\n",
    "            freeze_backbone (bool): If True, freeze the backbone layers.\n",
    "            hidden_sizes (Optional[List[int]]): List of sizes for hidden layers in the classifier.\n",
    "                If None, a single linear layer is used.\n",
    "            activation (str): Activation function to use in the classifier ('relu', 'tanh', etc.).\n",
    "        \"\"\"\n",
    "        super(BaseSwin, self).__init__()\n",
    "\n",
    "        # load Swin backbone from timm\n",
    "        self.backbone = timm.create_model(model_variant, pretrained=True, num_classes=num_classes)\n",
    "        self.backbone.reset_classifier(0)\n",
    "        \n",
    "        in_features = self.backbone.num_features\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Build the classifier based on the provided hidden_sizes\n",
    "        layers = []\n",
    "        input_dim = in_features\n",
    "        if hidden_sizes:\n",
    "            for hidden_dim in hidden_sizes:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(self._get_activation(activation))\n",
    "                input_dim = hidden_dim\n",
    "            # final classification layer.\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        else:\n",
    "            # single linear layer if no hidden layers specified\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(nn.Linear(input_dim, num_classes))\n",
    "        \n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "    \n",
    "    def _get_activation(self, activation: str) -> Callable:\n",
    "        \"\"\"Returns an activation function based on the given string.\n",
    "\n",
    "        Args:\n",
    "            activation (str): Name of the activation function.\n",
    "\n",
    "        Returns:\n",
    "            Callable: Activation function module.\n",
    "        \"\"\"\n",
    "        if activation.lower() == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation.lower() == 'leakyrelu':\n",
    "            return nn.LeakyReLU()\n",
    "        elif activation.lower() == 'gelu':\n",
    "            return nn.GELU()\n",
    "        elif activation.lower() == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.backbone.forward_features(x)\n",
    "        if features.ndim > 2:\n",
    "            features = features.mean(dim=[2, 3])\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model instantiated: BaseSwin\n",
      "BaseSwin(\n",
      "  (backbone): SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): SwinTransformerStage(\n",
      "        (downsample): Identity()\n",
      "        (blocks): Sequential(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.004)\n",
      "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.004)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerStage(\n",
      "        (downsample): PatchMerging(\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.009)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.009)\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.013)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.013)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): SwinTransformerStage(\n",
      "        (downsample): PatchMerging(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.017)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.017)\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.022)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.022)\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.026)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.026)\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.030)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.030)\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.035)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.035)\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.039)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.039)\n",
      "          )\n",
      "          (6): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.043)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.043)\n",
      "          )\n",
      "          (7): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.048)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.048)\n",
      "          )\n",
      "          (8): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.052)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.052)\n",
      "          )\n",
      "          (9): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.057)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.057)\n",
      "          )\n",
      "          (10): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.061)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.061)\n",
      "          )\n",
      "          (11): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.065)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.065)\n",
      "          )\n",
      "          (12): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.070)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.070)\n",
      "          )\n",
      "          (13): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.074)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.074)\n",
      "          )\n",
      "          (14): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.078)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.078)\n",
      "          )\n",
      "          (15): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.083)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.083)\n",
      "          )\n",
      "          (16): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.087)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.087)\n",
      "          )\n",
      "          (17): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.091)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.091)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): SwinTransformerStage(\n",
      "        (downsample): PatchMerging(\n",
      "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.096)\n",
      "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.096)\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.100)\n",
      "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.100)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (head): ClassifierHead(\n",
      "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "      (fc): Identity()\n",
      "      (flatten): Identity()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.3, inplace=False)\n",
      "    (7): Linear(in_features=128, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {device}\")\n",
    "model = BaseSwin(model_variant=\"swin_base_patch4_window7_224\",num_classes=4, dropout=0.3, freeze_backbone=True, hidden_sizes=[256, 128], activation='relu').to(device)\n",
    "print(\"Model instantiated:\", model.__class__.__name__)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "This is the part where you write the training function and load it to the ray tune scheduler.\n",
    "For this execution, ASHAscheduler is used with Optuna for bayesian optimisation techniques - which should be using the default Tree-Structured Parzen Estimator.\n",
    "If many parameters, this is would be more efficient than grid search and random search.\n",
    "\n",
    "References:\n",
    "- https://docs.ray.io/en/latest/tune/examples/includes/async_hyperband_example.html\n",
    "- https://docs.ray.io/en/latest/tune/examples/tune-pytorch-cifar.html \n",
    "- https://docs.ray.io/en/latest/tune/examples/includes/mnist_pytorch.html\n",
    "- https://docs.ray.io/en/latest/tune/api/suggestion.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = os.path.abspath(\"../models/hyptune/swin\")\n",
    "def train_model( config, device=device, checkpoint_dir=CHECKPOINT_DIR, data_dir=None):\n",
    "    \"\"\"Training function for Ray Tune hyperparameter tuning.\n",
    "\n",
    "    This function instantiates the model with hyperparameters\n",
    "    specified in the config dictionary, trains the model on the global TRAIN_LOADER,\n",
    "    evaluates on VAL_LOADER, and reports the validation loss to Ray Tune.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Hyperparameter configuration. Expected keys include:\n",
    "            - lr (float): Learning rate.\n",
    "            - weight_decay (float): Weight decay for the optimizer.\n",
    "            - dropout (float): Dropout rate for the classifier.\n",
    "            - hidden_sizes (list or None): List of hidden layer sizes in the classifier.\n",
    "            - activation (str): Activation function to use ('relu', 'tanh', etc.).\n",
    "            - freeze_backbone (bool): Whether to freeze the model backbone.\n",
    "            - num_epochs (int): Number of training epochs.\n",
    "            - optimiser (callable, optional): Optimiser class. Default is optim.Adam.\n",
    "            - criterion (callable, optional): Loss function instance. Default is nn.CrossEntropyLoss().\n",
    "        checkpoint_dir (str, optional): Directory for checkpointing (if applicable).\n",
    "        data_dir (str, optional): Not used here; included for compatibility.\n",
    "    \"\"\"\n",
    "    if checkpoint_dir:\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        print(f\"Checkpoint Folder exists\")\n",
    "    \n",
    "    # instantiate model with hyperparameters from config\n",
    "    model = BaseSwin(\n",
    "        num_classes=4,\n",
    "        dropout=config.get(\"dropout\", 0.3),\n",
    "        freeze_backbone=config.get(\"freeze_backbone\", True),\n",
    "        hidden_sizes=config.get(\"hidden_sizes\", None),\n",
    "        activation=config.get(\"activation\", \"relu\")\n",
    "    ).to(device)\n",
    "\n",
    "    optimiser = config[\"optimiser\"](model.parameters(), config[\"lr\"], config[\"weight_decay\"])\n",
    "    criterion = config[\"criterion\"]()\n",
    "\n",
    "    num_epochs = config.get(\"num_epochs\", 2)  # a low number for quick tuning, but update accordingly\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in tqdm(TRAIN_LOADER, position=0, leave=True, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(TRAIN_LOADER.dataset)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # optionally, can checkpoint the model\n",
    "        if checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, f\"checkpoint_{epoch}.pt\")\n",
    "            torch.save(model.state_dict(), path)\n",
    "    \n",
    "    # evaluation on the subset validation set\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in VAL_LOADER:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    avg_val_loss = total_loss / len(VAL_LOADER.dataset)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # Report the metric to Ray Tune\n",
    "    tune.report({\"loss\": avg_val_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-04-17 01:16:14</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:10.34        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.5/31.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 90.000: None | Iter 30.000: None | Iter 10.000: None<br>Logical resource usage: 4.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>t_7c39bbc6  </td><td style=\"text-align: right;\">           1</td><td>C:/Users/Ning/AppData/Local/Temp/ray/session_2025-04-17_01-16-00_545829_37336/artifacts/2025-04-17_01-16-03/baseswin/driver_artifacts/trial_7c39bbc6/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th>status  </th><th>loc            </th><th>activation  </th><th>criterion           </th><th style=\"text-align: right;\">  dropout</th><th>hidden_sizes  </th><th style=\"text-align: right;\">         lr</th><th>optimiser           </th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>t_8c250aeb  </td><td>PENDING </td><td>               </td><td>tanh        </td><td>&lt;function &lt;lamb_7760</td><td style=\"text-align: right;\"> 0.336681</td><td>[512, 256]    </td><td style=\"text-align: right;\">0.000265875</td><td>&lt;function &lt;lamb_68c0</td><td style=\"text-align: right;\">   2.3102e-05 </td></tr>\n",
       "<tr><td>t_7c39bbc6  </td><td>ERROR   </td><td>127.0.0.1:27724</td><td>tanh        </td><td>&lt;function &lt;lamb_7760</td><td style=\"text-align: right;\"> 0.446399</td><td>[256, 128]    </td><td style=\"text-align: right;\">0.000561152</td><td>&lt;function &lt;lamb_7640</td><td style=\"text-align: right;\">   0.000796945</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=27724)\u001b[0m Checkpoint Folder exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/63 [00:00<?, ?it/s]\n",
      "Epoch 1/10:   0%|          | 0/63 [00:00<?, ?it/s]\n",
      "2025-04-17 01:16:09,987\tERROR tune_controller.py:1331 -- Trial task failed for trial t_7c39bbc6\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\_private\\worker.py\", line 2782, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\_private\\worker.py\", line 929, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27724, ip=127.0.0.1, actor_id=51a793729377116947c2951801000000, repr=train_model)\n",
      "  File \"python\\\\ray\\\\_raylet.pyx\", line 1895, in ray._raylet.execute_task\n",
      "  File \"python\\\\ray\\\\_raylet.pyx\", line 1835, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 689, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 330, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\air\\_internal\\util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\Ning\\AppData\\Local\\Temp\\ipykernel_37336\\1357391327.py\", line 48, in train_model\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\Ning\\AppData\\Local\\Temp\\ipykernel_37336\\3003389351.py\", line 84, in forward\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x7 and 1024x256)\n",
      "2025-04-17 01:16:14,010\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-04-17 01:16:14,015\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/ray_results/swin/baseswin' in 0.0050s.\n",
      "2025-04-17 01:16:14,770\tERROR tune.py:1037 -- Trials did not complete: [t_7c39bbc6]\n",
      "2025-04-17 01:16:14,770\tINFO tune.py:1041 -- Total run time: 11.13 seconds (10.34 seconds for the tuning loop).\n",
      "2025-04-17 01:16:14,770\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"C:/ray_results/swin/baseswin\", trainable=...)\n",
      "2025-04-17 01:16:14,775\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 1 trial(s):\n",
      "- t_8c250aeb: FileNotFoundError('Could not fetch metrics for t_8c250aeb: both result.json and progress.csv were not found at C:/ray_results/swin/baseswin/trial_8c250aeb')\n",
      "2025-04-17 01:16:14,794\tWARNING experiment_analysis.py:558 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: loss. This means that no trial has reported this metric.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 83\u001b[0m\n\u001b[0;32m     64\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[0;32m     65\u001b[0m     tune\u001b[38;5;241m.\u001b[39mwith_resources(train_model, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}), \u001b[38;5;66;03m#NOTE: specify based on the device u using because by default it uses all, i.e if u have 4 cpus; it does 4 concurrent trials\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     tune_config\u001b[38;5;241m=\u001b[39mtune\u001b[38;5;241m.\u001b[39mTuneConfig(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     param_space\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     80\u001b[0m )\n\u001b[0;32m     82\u001b[0m results \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest config:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_nan_and_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\Ning\\anaconda3\\envs\\dog_emotions\\lib\\site-packages\\ray\\tune\\result_grid.py:161\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[1;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[0;32m    150\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No best trial found for the given metric: loss. This means that no trial has reported this metric."
     ]
    }
   ],
   "source": [
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='loss',\n",
    "    mode='min',\n",
    "    max_t=100,           # max training iterations per trial\n",
    "    grace_period=10,     # min iterations before stopping\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "optuna_search = OptunaSearch(metric=\"loss\", mode=\"min\", seed=42)\n",
    "\n",
    "# define search space in a config dictionary, i.e what are the values you want to try, this is just example of format\n",
    "'''\n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"dropout\": tune.uniform(0.1, 0.5),\n",
    "    \"hidden_sizes\": tune.choice([[256, 128], [512, 256], None]),\n",
    "    \"activation\": tune.choice([\"relu\", \"tanh\"]),\n",
    "    \"freeze_backbone\": tune.choice([True, False]),\n",
    "    \"num_epochs\": 2, \n",
    "    \"optimiser\": tune.choice([optim.Adam, optim.SGD]),\n",
    "    \"criterion\": tune.choice([nn.CrossEntropyLoss, nn.NLLLoss]),\n",
    "}\n",
    "'''\n",
    "\n",
    "# this is what i specified for the example because i am running on cpu\n",
    "# config = {\n",
    "#     \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "#     \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "#     \"dropout\": tune.uniform(0.1, 0.5),\n",
    "#     \"freeze_backbone\": tune.choice([True]),\n",
    "#     \"num_epochs\": 2,\n",
    "# }\n",
    "\n",
    "# for swin gpu\n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),    \n",
    "    \"weight_decay\": tune.loguniform(1e-5, 1e-3),\n",
    "    \"dropout\": tune.uniform(0.3, 0.5),\n",
    "    \"hidden_sizes\": tune.choice([[256, 128], [512, 256], None]),\n",
    "    \"activation\": tune.choice([\"relu\", \"tanh\", \"sigmoid\", \"leakyrelu\", \"gelu\"]),\n",
    "    \"freeze_backbone\": True,\n",
    "    \"num_epochs\": 10,\n",
    "    \"optimiser\": tune.choice([\n",
    "        lambda params, lr, wd: optim.Adam(params, lr=lr, weight_decay=wd),\n",
    "        lambda params, lr, wd: optim.SGD(params, lr=lr, momentum=0.9, weight_decay=wd)\n",
    "    ]),\n",
    "    \"criterion\": tune.choice([\n",
    "        lambda: nn.CrossEntropyLoss(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "def trial_dirname_creator(trial):\n",
    "    # this is meant to create short and unique directory name for each trial bc else too long for windows\n",
    "    # include a unique identifier (like trial.trial_id).\n",
    "    return f\"trial_{trial.trial_id}\"\n",
    "\n",
    "def trial_name_creator(trial):\n",
    "    return f\"t_{trial.trial_id}\"\n",
    "\n",
    "# tuner object\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(train_model, {\"cpu\": 4, \"gpu\": 1}), #NOTE: specify based on the device u using because by default it uses all, i.e if u have 4 cpus; it does 4 concurrent trials\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=asha_scheduler,\n",
    "        search_alg=optuna_search,\n",
    "        num_samples=15,  # number of trials to run\n",
    "        trial_dirname_creator=trial_dirname_creator,\n",
    "        trial_name_creator=trial_name_creator, \n",
    "    ),\n",
    "    run_config=tune.RunConfig(\n",
    "        name=\"baseswin\",\n",
    "        storage_path=\"C:/ray_results/swin\", #NOTE: not required for mac\n",
    "        log_to_file=True,\n",
    "        verbose=1,\n",
    "        ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "print(\"Best config:\", results.get_best_result(metric=\"loss\", mode=\"min\", filter_nan_and_inf=False).config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full best config: {'lr': 0.0015689271116954833, 'weight_decay': 6.220169739600738e-05, 'dropout': 0.3015094638632586, 'hidden_sizes': None, 'activation': 'relu', 'freeze_backbone': True, 'num_epochs': 10, 'optimiser': <function <lambda> at 0x0000020BE0445990>, 'criterion': <function <lambda> at 0x0000020BE0444B80>}\n"
     ]
    }
   ],
   "source": [
    "best_config = results.get_best_result(metric=\"loss\", mode=\"min\").config\n",
    "print(\"Full best config:\", best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Ning/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "final_model = BaseSwin(\n",
    "    num_classes=4,\n",
    "    dropout=best_config[\"dropout\"],\n",
    "    freeze_backbone=best_config[\"freeze_backbone\"],\n",
    "    hidden_sizes=best_config[\"hidden_sizes\"],\n",
    "    activation=best_config[\"activation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = final_model.to(device)\n",
    "logging.info(\"Model instantiated on device: %s\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = best_config[\"optimiser\"](final_model.parameters(), lr=best_config[\"lr\"], wd=best_config[\"weight_decay\"])\n",
    "criterion = best_config[\"criterion\"]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c37407a28046caa0eb985945c82c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 1.0809, Val Loss: 0.6030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae83a4945ac470e9eb49746c462d4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train Loss: 0.7806, Val Loss: 0.5848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5af08a3089a4261bbc8dc80f433d2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train Loss: 0.7635, Val Loss: 0.5523\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e896c5541840b9bf76a3e8347efdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train Loss: 0.7412, Val Loss: 0.5347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cf246d7d3446d885dd35f5da0316a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train Loss: 0.7470, Val Loss: 0.5728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e608ee6688d94fa38ed42cebee19ac1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train Loss: 0.7416, Val Loss: 0.5607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31b9bc3a30e4c45bd3cbb8e04930033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train Loss: 0.7556, Val Loss: 0.5695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45957957a97e488b8fa01ae700a16ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Train Loss: 0.7541, Val Loss: 0.5646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280d2e55dd6b44709f43e8210f0baaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Train Loss: 0.7388, Val Loss: 0.5602\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# early stopping parameters\n",
    "patience = 5  # the number of epochs to wait to see if got improvements\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "num_epochs_full = 50\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# training loop with early stopping\n",
    "for epoch in range(num_epochs_full):\n",
    "    final_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in tqdm(FULL_TRAIN_LOADER, desc=f\"Epoch {epoch+1}/{num_epochs_full}\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimiser.zero_grad()\n",
    "        outputs = final_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_train_loss = running_loss / len(FULL_TRAIN_LOADER.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    logging.info(\"Epoch %d: Training Loss: %.4f\", epoch+1, epoch_train_loss)\n",
    "    \n",
    "    # evaluate on the validation set\n",
    "    final_model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in FULL_VAL_LOADER:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = final_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_val_loss += loss.item() * inputs.size(0)\n",
    "    epoch_val_loss = running_val_loss / len(FULL_VAL_LOADER.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    logging.info(\"Epoch %d: Validation Loss: %.4f\", epoch+1, epoch_val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_full} - Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "    \n",
    "    # if no improvement then early stopping\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        # save the best model\n",
    "        best_model_path = os.path.join(MODEL_SAVE_DIR, \"swin_best_model.pt\") #NOTE: specify by model\n",
    "        torch.save(final_model.state_dict(), best_model_path)\n",
    "        logging.info(\"Model saved to: %s\",  {best_model_path})\n",
    "        logging.info(\"Epoch %d: New best model saved.\", epoch+1)\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        logging.info(\"Early stopping triggered at epoch %d\", epoch+1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from training\n",
    "final_model.load_state_dict(torch.load(best_model_path))\n",
    "final_model.to(device)\n",
    "final_model.eval()\n",
    "\n",
    "# initialise metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in FULL_TEST_LOADER:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = final_model(images)\n",
    "        # for test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        # for accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy()) # move to cpu to ensure compatibility because numpy only operates on cpu\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(FULL_TEST_LOADER.dataset)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "logging.info(\"Test Loss: %.4f, Test Accuracy: %.2f%%\", test_loss, test_accuracy * 100)\n",
    "\n",
    "# plotting training and validation loss curves\n",
    "if 'train_losses' in globals() and 'val_losses' in globals():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses)+1), train_losses, label=\"Training Loss\")\n",
    "    plt.plot(range(1, len(val_losses)+1), val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Curves\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    loss_curve_path = os.path.join(\"..\", \"results\", \"swin\", \"loss_curves.png\") #NOTE: specify by model name\n",
    "    plt.savefig(loss_curve_path)\n",
    "    plt.show()\n",
    "    logging.info(\"Training and Validation Loss curves saved to %s\", loss_curve_path)\n",
    "else:\n",
    "    logging.warning(\"train_losses and val_losses are not defined. Skipping loss curves plot.\")\n",
    "\n",
    "# generate and log classification report\n",
    "class_names = FULL_TEST_LOADER.dataset.classes\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "logging.info(\"Classification Report:\\n%s\", report)\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# save confusion matrix as image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "conf_matrix_path = os.path.join(\"..\", \"results\", \"swin\", \"confusion_matrix.png\") #NOTE: specify by model name\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.show(fig)\n",
    "\n",
    "logging.info(\"Confusion matrix saved to: %s\", conf_matrix_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog_emotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
