{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c109bc7",
   "metadata": {},
   "source": [
    "# Image Dataset Preperation\n",
    "This notebook contains the code for cleaning and preparing the dataset to be used for the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ac537",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Used to handle the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a458e220",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgdown\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelperFunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_rgb\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gdown'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import numpy as np\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "from utils.helperFunctions import is_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ba49d",
   "metadata": {},
   "source": [
    "## File Location Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a596dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_directory = \"inputs\"\n",
    "data_set_creation_working_dir = \"imageMaker\"\n",
    "root = \"..\"\n",
    "raw_data_folder = \"dog_emotion\"\n",
    "processed_data_folder = \"dog_emotion_rgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bff427d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\inputs\n",
      "..\\imageMaker\n"
     ]
    }
   ],
   "source": [
    "# Create output folder if it doesn't exist\n",
    "\n",
    "RAW_IMAGE_INPUT_DIR = os.path.join(root, data_set_directory)\n",
    "IMAGE_PROCESSING_SUBFOLDER = os.path.join(root, data_set_creation_working_dir)\n",
    "print(RAW_IMAGE_INPUT_DIR)\n",
    "\n",
    "print(IMAGE_PROCESSING_SUBFOLDER)\n",
    "os.makedirs(IMAGE_PROCESSING_SUBFOLDER, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd99553",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading dataset from Gdrive\n",
    "if not os.path.exists(\"../input/final_split\"):\n",
    "    # os.makedirs(\"../input/actual\")\n",
    "    output_path = \"../input/final_split.zip\"\n",
    "    gdown.download(f\"https://drive.google.com/uc?id=11t8m703wcNss3w5diJSUGBA_vXnCKChr\", output_path, quiet=False)\n",
    "    with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"../input\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed7b70",
   "metadata": {},
   "source": [
    "## Step 1: Remove Black & White Images\n",
    "Filters out grayscale images to improve training quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3899ec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Preprocessing Summary:\n",
      "Total images scanned      : 0\n",
      "Black & white images      : 0\n",
      "Images removed            : 0\n",
      "Images successfully kept  : 0\n",
      "Images skipped (corrupted): 0\n",
      "‚úÖ RGB images saved in: ..\\imageMaker\n"
     ]
    }
   ],
   "source": [
    "# Counters\n",
    "total_images = 0\n",
    "bw_images = 0\n",
    "copied_images = 0\n",
    "skipped_images = 0\n",
    "\n",
    "# Scan and filter images\n",
    "for root, _, files in os.walk(RAW_IMAGE_INPUT_DIR):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            total_images += 1\n",
    "            path = os.path.join(root, filename)\n",
    "            if is_rgb(path):\n",
    "                # Preserve subfolder structure\n",
    "                relative_path = os.path.relpath(path, RAW_IMAGE_INPUT_DIR)\n",
    "                destination = os.path.join(IMAGE_PROCESSING_SUBFOLDER, relative_path)\n",
    "                os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "                shutil.copy(path, destination)\n",
    "                copied_images += 1\n",
    "            else:\n",
    "                print(f\"Removed (Not RGB): {filename}\")\n",
    "                bw_images += 1\n",
    "\n",
    "# Skipped due to load errors\n",
    "skipped_images = total_images - (copied_images + bw_images)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüìä Preprocessing Summary:\")\n",
    "print(f\"Total images scanned      : {total_images}\")\n",
    "print(f\"Black & white images      : {bw_images}\")\n",
    "print(f\"Images removed            : {bw_images + skipped_images}\")\n",
    "print(f\"Images successfully kept  : {copied_images}\")\n",
    "print(f\"Images skipped (corrupted): {skipped_images}\")\n",
    "print(f\"‚úÖ RGB images saved in: {IMAGE_PROCESSING_SUBFOLDER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3750ff8",
   "metadata": {},
   "source": [
    "## Step 2: Detect, Crop, and Resize Dog Faces\n",
    "Uses YOLOv8 to detect dog faces, crops them, and resizes to 224x224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Directories\n",
    "input_dir = \"datasets/dog_emotion_rgb\"\n",
    "output_dir = \"datasets/dog_faces_224\"\n",
    "no_detect_log = \"no_dogs_detected.txt\"\n",
    "\n",
    "# Load YOLOv8 model\n",
    "print(\"üì¶ Loading YOLOv8 model...\")\n",
    "model = YOLO(\"yolov8x.pt\") \n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"‚úÖ YOLOv8 loaded.\\n\")\n",
    "\n",
    "# Counters\n",
    "total = 0\n",
    "detected = 0\n",
    "no_dog = 0\n",
    "\n",
    "# Clear old log if exists\n",
    "if os.path.exists(no_detect_log):\n",
    "    os.remove(no_detect_log)\n",
    "\n",
    "# Start processing\n",
    "for root, _, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if not file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(root, file)\n",
    "        relative_path = os.path.relpath(img_path, input_dir)\n",
    "        save_path = os.path.join(output_dir, relative_path)\n",
    "\n",
    "        print(f\"üì∑ Processing: {img_path}\")\n",
    "\n",
    "        try:\n",
    "            results = model(img_path, conf=0.15)  # lowered threshold\n",
    "            result = results[0]\n",
    "            dog_found = False\n",
    "\n",
    "            for box in result.boxes:\n",
    "                class_id = int(box.cls)\n",
    "                if class_id == 16:  # class 16 = dog\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "                    img = Image.open(img_path).convert(\"RGB\")\n",
    "                    cropped = img.crop((x1, y1, x2, y2)).resize((224, 224))\n",
    "                    cropped.save(save_path)\n",
    "\n",
    "                    print(f\"‚úÖ Saved cropped dog to {save_path}\")\n",
    "                    detected += 1\n",
    "                    dog_found = True\n",
    "                    break\n",
    "\n",
    "            if not dog_found:\n",
    "                with open(no_detect_log, \"a\") as f:\n",
    "                    f.write(f\"{img_path}\\n\")\n",
    "                print(\"üê∂ No dog class (16) detected.\")\n",
    "                no_dog += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error processing {img_path}: {e}\")\n",
    "        \n",
    "        total += 1\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüìä Step 2 Summary:\")\n",
    "print(f\"Total images processed : {total}\")\n",
    "print(f\"Dog detections         : {detected}\")\n",
    "print(f\"No detections          : {no_dog}\")\n",
    "print(f\"Saved to folder        : {output_dir}\")\n",
    "print(f\"No-dog image log       : {no_detect_log}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8356d79",
   "metadata": {},
   "source": [
    "## Step 3: Split Dataset\n",
    "Splits the cleaned dataset into 70% training, 15% validation (test), and 15% final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736cdd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "input_folder = 'datasets/dog_faces_224/Dog Emotion'\n",
    "output_base = 'datasets/final_split'\n",
    "\n",
    "# Splits\n",
    "split_ratios = {\n",
    "    'train': 0.7,\n",
    "    'test': 0.15,\n",
    "    'eval': 0.15\n",
    "}\n",
    "\n",
    "# Seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Clear and recreate output folders\n",
    "for split in split_ratios:\n",
    "    split_path = os.path.join(output_base, split)\n",
    "    if os.path.exists(split_path):\n",
    "        shutil.rmtree(split_path)\n",
    "    os.makedirs(split_path)\n",
    "\n",
    "total_images = 0\n",
    "split_counts = {'train': 0, 'test': 0, 'eval': 0}\n",
    "\n",
    "# For each class folder\n",
    "for class_folder in os.listdir(input_folder):\n",
    "    print(f\"üìÇ Found folder: {class_folder}\")\n",
    "    class_path = os.path.join(input_folder, class_folder)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    images = [img for img in os.listdir(class_path) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"üñºÔ∏è  Found {len(images)} images in {class_folder}\")\n",
    "\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n = len(images)\n",
    "    n_train = int(n * split_ratios['train'])\n",
    "    n_test = int(n * split_ratios['test'])\n",
    "    n_eval = n - n_train - n_test\n",
    "\n",
    "    split_lists = {\n",
    "        'train': images[:n_train],\n",
    "        'test': images[n_train:n_train + n_test],\n",
    "        'eval': images[n_train + n_test:]\n",
    "    }\n",
    "\n",
    "    for split, split_imgs in split_lists.items():\n",
    "        for img_name in split_imgs:\n",
    "            src = os.path.join(class_path, img_name)\n",
    "            dst_dir = os.path.join(output_base, split, class_folder)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            shutil.copy(src, os.path.join(dst_dir, img_name))\n",
    "            split_counts[split] += 1\n",
    "\n",
    "    total_images += n\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüìä Step 3 Summary:\")\n",
    "print(f\"Total images processed : {total_images}\")\n",
    "for split in split_ratios:\n",
    "    print(f\"{split.capitalize()} images        : {split_counts[split]}\")\n",
    "print(f\"‚úÖ Data split saved in: {output_base}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99249865",
   "metadata": {},
   "source": [
    "## Step 4: Augment Training Data\n",
    "Applies horizontal flip, rotation, and color jitter to boost training diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "\n",
    "# Input/output folders\n",
    "input_folder = 'datasets/final_split/train'\n",
    "output_folder = 'datasets/final_split/train_aug_15apr2025'\n",
    "\n",
    "# Define augmentation transforms\n",
    "augmentation_pipeline = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.Resize((224, 224))\n",
    "])\n",
    "\n",
    "# Make sure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Set number of augmentations per image\n",
    "NUM_AUGMENTATIONS = 2\n",
    "\n",
    "total_images = 0\n",
    "augmented_images = 0\n",
    "\n",
    "for root, _, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            total_images += 1\n",
    "            input_path = os.path.join(root, file)\n",
    "\n",
    "            # Load image\n",
    "            try:\n",
    "                img = Image.open(input_path).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Skipping {input_path} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Reconstruct class subfolder path\n",
    "            relative_path = os.path.relpath(root, input_folder)\n",
    "            class_output_dir = os.path.join(output_folder, relative_path)\n",
    "            os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "            # Save original (resized) image\n",
    "            original_resized = transforms.Resize((224, 224))(img)\n",
    "            original_resized.save(os.path.join(class_output_dir, file))\n",
    "\n",
    "            # Generate augmented images\n",
    "            for i in range(NUM_AUGMENTATIONS):\n",
    "                augmented = augmentation_pipeline(img)\n",
    "                aug_filename = f\"{os.path.splitext(file)[0]}_aug{i+1}.jpg\"\n",
    "                augmented.save(os.path.join(class_output_dir, aug_filename))\n",
    "                augmented_images += 1\n",
    "\n",
    "print(\"\\nüìä Step 4 Summary:\")\n",
    "print(f\"Total original images     : {total_images}\")\n",
    "print(f\"Augmented images created  : {augmented_images}\")\n",
    "print(f\"‚úÖ Augmented data saved in: {output_folder}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearnin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
